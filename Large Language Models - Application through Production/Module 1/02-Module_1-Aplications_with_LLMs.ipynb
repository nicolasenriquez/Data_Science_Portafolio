{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 - Applications with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Hugging Face Overview - How to Select a Model**\n",
    "\n",
    "If I want to summarize a text, and search for a model in hagging face, it has about 176.000 models, and if we filter by \"summarize\", we get into the thousend models. So what's next?\n",
    "\n",
    "There are a lot of potential\n",
    "requirements and needs, and a lot of\n",
    "techniques to filter by them.\n",
    "\n",
    " 1) Let's look at some easy choices first.\n",
    "Filtering by task in the upper left, license,\n",
    "language: these kinds of hard constraints\n",
    "can be pretty easy and pretty useful.\n",
    "For example if you need a commercially\n",
    "permissive license,\n",
    "that can be pretty clear-cut.\n",
    "Look up how large these models are, either in Files and\n",
    "Versions to get an idea of maybe\n",
    "the number of gigabytes the PyTorch\n",
    "representation takes, or if the model is\n",
    "well documented the number of parameters\n",
    "it has.\n",
    "That can be important if you need to\n",
    "limit hardware requirements for cost or\n",
    "latency or whatever.\n",
    "Updates matter; especially if you are\n",
    "looking at a very old model, it might not\n",
    "even load properly with the latest\n",
    "Transformers library.\n",
    "If you want more details about what is\n",
    "in these updates to models, it can be useful\n",
    "to check the git release history.\n",
    "Well-documented models will document\n",
    "that.\n",
    "\n",
    "2) Let's talk about model variants, examples, and data.\n",
    "On the left I'm recommending to pick\n",
    "good variants of models for your tasks.\n",
    "Here's what I mean. When a famous model,\n",
    "say T5 is published, it's often published with\n",
    "different sizes: base, a smaller version,\n",
    "a larger version, maybe an even larger\n",
    "version. Here I'd say **start prototyping with the\n",
    "smallest one, just to get moving quickly,\n",
    "keep costs low. You can always move to a\n",
    "bigger version which will presumably be\n",
    "more powerful**.\n",
    "Not all models are well-documented,\n",
    "so a good example of usage\n",
    "will tell you not only what\n",
    "parameters you may want to tweak or\n",
    "whatever.\n",
    "It can also help you avoid needing to\n",
    "know about model architectures. You don't\n",
    "need to be an LLM expert in order to\n",
    "pick a good model, especially if you can\n",
    "find where someone has already shown it\n",
    "to be good for your task.\n",
    "\n",
    "3) Look for fine-tuned variants of\n",
    "base models, basically, if a\n",
    "model you pick has been fine-tuned on\n",
    "a dataset or a task very similar to yours,\n",
    "it may perform better. Is the model a generalist (good\n",
    "at everything) or was it fine-tuned to be\n",
    "great at a specific task? Relatedly, which\n",
    "datasets were used for pre-training\n",
    "and/or fine-tuning?\n",
    "Fine-tuned models in general are going\n",
    "to be smaller and or perform better if\n",
    "they match the task that you are doing.\n",
    "Ultimately though, it's about your data\n",
    "and users, so define KPIs and metrics,\n",
    "test on your data and users.\n",
    "\n",
    "4) The other part of selecting a model is recognizing famous good ones.\n",
    "\n",
    "5) Other things which are really important\n",
    "of course are model architecture,\n",
    "what datasets were used for\n",
    "pre-training and/or fine-tuning,\n",
    "and these can cause major differences\n",
    "between these models.\n",
    "That said, a lot of these foundation models\n",
    "really are interrelated, sharing\n",
    "or selecting from sort of a shared\n",
    "family of techniques or pre-training\n",
    "datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Common NLP Tasks**\n",
    "\n",
    "Here is a list of many of the regular tasks that NLP is used for (the ones in bold, are going to be reviewed in the course):\n",
    "- **Summarization**\n",
    "- **Sentiment Analysis**\n",
    "- **Translation**\n",
    "- **Zero-Shot Classification**\n",
    "- **Few-Shot Learning**\n",
    "\n",
    "\n",
    "- Conversation / Chat\n",
    "- (Table) Question-Answering\n",
    "- Text / Token Classificacion\n",
    "- Text Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Prompt Engineering**\n",
    "\n",
    "**Prompt engineering is model-specific**.\n",
    "So prompts will guide a model to complete\n",
    "the task in the way you wanted, but\n",
    "different models may require different\n",
    "prompts. And a lot of guidelines you'll\n",
    "see out there are specific to one\n",
    "of the most popular services, ChatGPT\n",
    "and its underlying OpenAI models.\n",
    "They may not work for non-ChatGPT\n",
    "models, but a lot of the techniques do\n",
    "carry over, even if the specific texts of\n",
    "the prompts do not.\n",
    "Different use cases may require\n",
    "different prompts, and so iterative\n",
    "development is key, hence engineering.\n",
    "\n",
    "\n",
    "\n",
    "> **General Tips for Prompt Engineering**\n",
    "- **A good prompt needs to be\n",
    "clear and specific**.\n",
    "Just like when you ask a human to do\n",
    "something you need to be clear and\n",
    "specific, that helps with LLMs as well.\n",
    "A good prompt often consists of an\n",
    "instruction, some context or background\n",
    "information, an input or question,\n",
    "output type or format.\n",
    "You should describe the high level task\n",
    "with clear commands. That may mean\n",
    "specific keywords like Classify,\n",
    "Translate, so on,\n",
    "or including detailed instructions.\n",
    "And finally, this is engineering, so test\n",
    "different variations of the prompt\n",
    "across different samples. Use a\n",
    "data-driven approach here: what prompt does\n",
    "better on average for your set of inputs.\n",
    "\n",
    "- There are also techniques for helping\n",
    "the model to reach a better answer,\n",
    "to sort of think better, you can tell the **model not to**,\n",
    "and that can help to delivered a better answer.\n",
    "You can **ask the model not to make\n",
    "things up**. You've probably heard of the\n",
    "term hallucination, where models will\n",
    "sometimes just spout nonsense or false\n",
    "things.\n",
    "You can also ask the **model not to assume\n",
    "or probe for sensitive information**,\n",
    "and finally this last one is very\n",
    "powerful. Ask the **model not to rush to a\n",
    "solution, but instead take more time to\n",
    "think** using what's called chain of\n",
    "thought reasoning. Things like: explain\n",
    "how you would solve this problem, or do\n",
    "this step-by-step.\n",
    "\n",
    "- A technique for reducing prompt hacking,\n",
    "You can post-process or filter.\n",
    "Use another model to clean the output,\n",
    "or tell the model to remove all\n",
    "offensive words from the output.\n",
    "\n",
    "- Another technique is to repeat instructions or sandwich\n",
    "instructions at the end.\n",
    "This can help them pay attention to what\n",
    "you really wanted to do.\n",
    "You can enclose user input with random\n",
    "strings or tags. That makes it easier for\n",
    "the model to distinguish what the user\n",
    "input is versus your instructions.\n",
    "\n",
    "- If all else fails, it can help to select a different model or restrict prompt length.\n",
    "\n",
    "\n",
    "\n",
    "- Prompt formatting can also be important. **Use delimiters to distinguish between\n",
    "the instruction and the context**.\n",
    "Also use them to distinguish between the\n",
    "user input, if this is a user-facing\n",
    "application, and the prompt that you add\n",
    "around it.\n",
    "Ask the model to return structured\n",
    "output, and provide a correct example. Prompt formatting can help prevent exploit vulnerabilities:\n",
    "    - **Prompt Injection**: trying to get the LLM to ignore the real instruction which\n",
    "the application wants it to follow,\n",
    "and instead override it with a user input\n",
    "instruction to add malicious content.\n",
    "    - **Prompt Leaking**: extracting sensitive information from a model.\n",
    "    - **Jailbraking**: bipassing a moderation rule. Here it's asking how to do something illegal, and the model first says, I can't tell you, and then some rephrasing, and the model actually answers the user question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LMS have a ton of wide-ranging use cases such as: summaarization, translation, sentiment analysis, few-show learning, zero-shot classification, etc.\n",
    "\n",
    "- Hugging Face provides many NLP components, plus a hub with downloadable models, datasets, and examples.\n",
    "\n",
    "- To select a model, think about your task, think about hard constraints, soft constraints, model size, and so on.\n",
    "\n",
    "- Prompt engineering is crucial for generating useful responses from these very powerful models. There are a lot of techniques and tips out there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
