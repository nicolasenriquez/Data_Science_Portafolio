{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Module 3 - Multi-Stage Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Introduction**\n",
    "\n",
    "Till now we saw how we can download large language models from places like hugging face to solve various tasks in NLP and\n",
    "we also saw how we can convert our data\n",
    "to vector format and perform vector type\n",
    "searches using vector databases. You\n",
    "might be wondering then, how can we\n",
    "combine these two features together to\n",
    "really enhance the applications that I\n",
    "can build as a developer? In this module\n",
    "we'll show you exactly how you can do\n",
    "that with the various tools that are\n",
    "available.\n",
    "By the end of the module, you'll be able\n",
    "to describe the flow of LLM pipelines\n",
    "with tools like LangChain, you'll use\n",
    "LangChain to build\n",
    "pipelines that involve llms from various\n",
    "providers including OpenAI and hugging\n",
    "face, and then we'll build really complex\n",
    "logical flow patterns using agents that\n",
    "leverage llms as the centralized brain\n",
    "and different tools that they can use to\n",
    "solve the tasks that they're given.\n",
    "\n",
    "\n",
    "> **LLMs Limitations**\n",
    "\n",
    "LLMs are fantastic at solving traditional NLP tasks we might give it a summarization task and it performs that fantastically. We might ask it to translate some text and it does that almost flawlessly. Zero shot classification, it does depending on how well the model has been\n",
    "trained for. All of these different\n",
    "things LLMs are fantastic at.\n",
    "However, most workflows that we think about involve more than just this simple input and output response. Typically for building an application\n",
    "the **LLM will just be one part of the\n",
    "entire workflow of this end-to-end\n",
    "application that we're designing**\n",
    "so we need to think about **how we can\n",
    "link together LLMs and other pieces of\n",
    "our code so that they work seamlessly\n",
    "together** and then if we need to maybe\n",
    "swap in at one LLM for another it\n",
    "doesn't break the entire end-to-end\n",
    "system.\n",
    "The **goal of the multi-stage reasoning\n",
    "module that we're talking about now is\n",
    "to show you how these tools can be built up\n",
    "so that it's modularized in a sense that\n",
    "you could take out an LLM and put a\n",
    "different one in**.\n",
    "\n",
    "For example, if we want to perform a sentiment analysis over a bunch of news articles, an intelligent approach will be to take one\n",
    "article at a time, pass it through a\n",
    "summarization large language model (LLM nº1) and\n",
    "then the output of that summary could\n",
    "then be given to a sentiment analysis\n",
    "large language model (LLM nº2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **LLM Chains - Linking Multiple LLM Interactions to build Complexity & Functionality**\n",
    "\n",
    "\n",
    "LLM chains where we can link together not just one llm with another but even a variety of different tools.  In this section we're going to talk\n",
    "about how LangChain does what it does and what we can do with large language models to connect not just other LLM but different tools as well.\n",
    "\n",
    "Let's go back to our example where we've\n",
    "finished taking in article, summarizing\n",
    "them and creating\n",
    "a prompt template to do that summary. We\n",
    "now need to create another prompt\n",
    "template so that we can take our\n",
    "sentiment analysis\n",
    "and put that into our workflow.\n",
    "So we're going to create a new sentiment\n",
    "prompt template like we did for the\n",
    "summarization,\n",
    "and we're going to say evaluate the\n",
    "sentiment of the following summary and\n",
    "then pass in that summary.\n",
    "The llm is then going to be requested to\n",
    "produce the sentiment so this is very\n",
    "similar to what we saw before we're just\n",
    "finishing the loop of this problem. So we\n",
    "have our two large language models they\n",
    "could come from the same provider, they\n",
    "might be different ones, depending on how\n",
    "we want to leverage the resources we\n",
    "have at hand we might use a large\n",
    "language model that's fine-tuned for\n",
    "summarization and one that's fine-tuned\n",
    "for sentiment.\n",
    "\n",
    "If we have our large language\n",
    "model trained well enough or trained\n",
    "specifically enough we can use it as a\n",
    "central reasoning tool and give it\n",
    "different types of\n",
    "access to things like search engines,\n",
    "email clients, other large language\n",
    "models, the whole world really of the\n",
    "internet is open to what these large\n",
    "language models can do.\n",
    "As long as we phrase our input our\n",
    "prompts such that the response from the\n",
    "llm would contain code or snippets of\n",
    "code that would interact with some kind\n",
    "of API and it can receive back the\n",
    "results of that API call we can have our\n",
    "llm actually connect to almost anything\n",
    "programmatic that we have.\n",
    "We can do this in a structured way, we\n",
    "could even do this in a way that the llm\n",
    "decides for itself what tools it should\n",
    "use.\n",
    "We'll focus on how these models decide\n",
    "what to do with their tools in the next\n",
    "section when we talk about llm agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **LLM Agents**\n",
    "\n",
    "LLM agent uses a large language model as a centralized\n",
    "reasoning unit and attaches tools and\n",
    "other components so that we can ask it\n",
    "to solve some very complicated tasks\n",
    "almost automatically.\n",
    "An llm agent is built up of these\n",
    "reasoning loops that large language\n",
    "models have shown to be very adapted performing. A large language model can be given a task and we can ask it to provide a plan or a thought process of how it would complete this task. We can then utilize this step-by-step approach and force the llm to go through a thought action and observation loop.\n",
    "\n",
    "It can take that request look at the\n",
    "description of the tools that it has at\n",
    "its disposal and decide what to do next.\n",
    "It can then observe the result of\n",
    "performing that action with that\n",
    "particular tool and make the judgment as\n",
    "to whether or not it should stop and\n",
    "return with a completed task,\n",
    "or take another step and go through the\n",
    "process taking the results that it\n",
    "currently has and putting that into the\n",
    "input of the LLM to the next step.\n",
    "It continues this process until either a\n",
    "maximum amount of iterations has been\n",
    "performed or until it sees some kind of\n",
    "stopping criteria.\n",
    "This makes LLM agents a very powerful\n",
    "tool in solving very complicated\n",
    "problems.\n",
    "\n",
    "To build an llm agent, we first need a\n",
    "task that it needs to solve we need an\n",
    "llm that's capable of performing good\n",
    "Chain of Thought reasoning,\n",
    "and we need a set of tools that can\n",
    "interface with our large language model.\n",
    "In the same way that we saw the\n",
    "mathematical tool used previously with\n",
    "our llm chains.\n",
    "The tool descriptions are useful because\n",
    "the llm will look at the request of the\n",
    "tasks that it has to perform it'll look\n",
    "at the description of the tool and it'll\n",
    "decide which one it should use and how\n",
    "it should interface with it.\n",
    "Because llms often have the ability to\n",
    "output code or API interaction code with\n",
    "their output we can then leverage this\n",
    "fact to interact with different types of\n",
    "numerical or computational components.\n",
    "Llm agents or llm plugins are just\n",
    "starting to be released to the public\n",
    "and developed by the open source\n",
    "community.\n",
    "LangChain was the first largely used\n",
    "open source application of llm agents\n",
    "but the rest of the community is quickly\n",
    "taking notice and producing similar\n",
    "types of products, Hugging Face just\n",
    "released their transformers agents a few\n",
    "weeks ago.\n",
    "Google at their I/O conference this year\n",
    "showed the integration of PaLM 2 with\n",
    "their workspace,\n",
    "and ChatGPT is slowly releasing the\n",
    "plugins feature to the public where we\n",
    "can connect different types of tools to\n",
    "the ChatGPT interface and have it\n",
    "complete really interesting and complex\n",
    "tasks for us.\n",
    "\n",
    "Now if we want to take this to an\n",
    "extreme level, we can actually give the\n",
    "llm more automative abilities and allow\n",
    "it to create copies of itself so that it\n",
    "can solve tasks even given just a small\n",
    "amount of prompting.\n",
    "In the early months of 2023, a new\n",
    "product or a new repo rather was\n",
    "created under the name AutoGPT\n",
    "AutoGPT uses GPT-4 to create clones of\n",
    "itself and delegates tasks to these\n",
    "copies so that it can solve truly\n",
    "complicated and fascinating tasks with\n",
    "just a natural language prompt.\n",
    "These multi-stage reasoning tools\n",
    "therefore, are starting to form a bit of\n",
    "a landscape we have differences in\n",
    "products based on whether they're\n",
    "proprietary or open source and whether\n",
    "whether or not they're guided like the\n",
    "structured building blocks we have for\n",
    "LangChain and Hugging Face transformers\n",
    "and then some of the unguided ones like\n",
    "the HuggingGPT or the babyAGI and\n",
    "AutoGPT\n",
    "projects that are currently being worked\n",
    "on by the open source community.\n",
    "I highly recommend you checking out all\n",
    "of these as they're very fascinating and\n",
    "continuously being updated to share some\n",
    "amazing abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We looked at how llm chains help us to build a structured format for our workflow so that we can combine our prompt templates with specific, task specific LLMs to produce the results that we want piece by piece.\n",
    "\n",
    "- We saw that LangChain can provide a wrapper around these chains so that it's easier to build and leverage different tools and architectures so that we can have our LLMs perform very different tasks, not just natural language processing but also compiling code and running different types of complex logic.\n",
    "\n",
    "- How llm agents can perform some truly amazing tasks that we're yet to see the full potential of."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
