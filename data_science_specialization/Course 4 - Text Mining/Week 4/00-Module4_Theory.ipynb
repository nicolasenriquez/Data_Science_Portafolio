{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Text Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the Semantic Text Similarity between words using Python\n",
    "\n",
    "- **WordNet is easily imported into Python through NLTK and it helps find the appropiate sense of the words (it's important to define whats it's considered to be appropiate)**\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "from nltk.corpus import webnet as wn\n",
    "\n",
    "deer = wn.synset(\"deer.n.01\")\n",
    "elk = wn.synset(\"elk.n.01\")\n",
    "horse = wn.synset(\"horse.n.01\")```\n",
    "\n",
    "\n",
    "- **Find the Path Similarity**\n",
    "\n",
    "```python\n",
    "deer.path_similarity(elk) # --> 0.5\n",
    "deer.path_similarity(horse) # --> 0.1428```\n",
    "\n",
    "\n",
    "- **Use the information criteria to find the Linear Similarity**\n",
    "\n",
    "```python\n",
    "from nltk.corpus import webnet_ic\n",
    "\n",
    "brown_ic = wordnet_ic.ic(\"ic-brown.dat\")\n",
    "deer.lin_similarity(elk, brown_ic) # --> 0.7726\n",
    "deer.lin_similarity(horse, brown_ic) # --> 0.8623```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations and Distributional Similarity\n",
    "\n",
    "\n",
    "- What is Collocations?\n",
    "    - *\"You know a word by the company it keeps (First, 1957)\"*\n",
    "    - Two words that frequently appears in similar contexts are more likely to be semantically related\n",
    "    - For example:\n",
    "        - The friends **met at** a **<font color='red'>café</font>**\n",
    "        - Shyam **met** Ray **at** a **<font color='red'>pizzeria</font>**\n",
    "        - Let's **meet** up **near the** **<font color='red'>coffee shop</font>**\n",
    "        - The secret **meeting at the** **<font color='red'>restaurant</font>** soon became public\n",
    "        \n",
    "\n",
    "\n",
    "### Distributional Similarity: Context\n",
    "\n",
    "- Words that are before and after the specific word, considered within a small window or neighbors\n",
    "\n",
    "- Parts-Of-Speech (POS) of words that are before and after the specific word, considered within a small window or neighbors\n",
    "\n",
    "- Specific syntactic relation to the target word\n",
    "\n",
    "- Words in the same sentence, same documents, ...\n",
    "\n",
    "\n",
    "\n",
    "### Strengh of Association between Words\n",
    "\n",
    "- How frequent are these inside the document\n",
    "    - Not similar if two words don't occure together often \n",
    "\n",
    "\n",
    "- Also it's important to see how frequent are individual words\n",
    "    - The word *the* is very frequent in the english languje, so it's a high chance it co-occurs often with every other word\n",
    "    \n",
    "    \n",
    "- Pointwise Mutual Information **(PMI)**: $$PMI(w, c) = log(\\frac{P(w, c)}{P(w) · P(c)})$$\n",
    "\n",
    "\n",
    "\n",
    "### How to Apply this in Python\n",
    "\n",
    "- Use NLTK Collocations and Association measures, also finder has other useful functions such as frequency filter\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "bigrams_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(text)\n",
    "\n",
    "finder.nbest(bigrams_measures.pmi, 10)\n",
    "finder.apply_freq_filter(10)```\n",
    "\n",
    "\n",
    "\n",
    "### Take Home Concepts\n",
    "\n",
    "- Finding similarity between words and text is a non-trivial task\n",
    "\n",
    "- WordNet is a useful resource for semantic relationships between words\n",
    "\n",
    "- Many similarity functions exist to help with several tasks\n",
    "\n",
    "- NLTK is a useful package for many such tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Topic Modeling?\n",
    "\n",
    "- A course-level analysis of what's in a text collection\n",
    "\n",
    "- *Topic*: the subject or theme of a discorse or a scientific paper, ...\n",
    "\n",
    "- Topics are represented as a word distribution \n",
    "\n",
    "- A document is assumed to be a mixture of topics\n",
    "\n",
    "\n",
    "\n",
    "- What's known:\n",
    "    - The text collection or also known as *corpus*\n",
    "    - The number of topics (for example 4 topics sush as sport, science, cooking, gameing)\n",
    "\n",
    "\n",
    "\n",
    "- What's not known:\n",
    "    - The actual topics\n",
    "    - The topic distribution for each document (40% sports, 60% genetics)\n",
    "\n",
    "\n",
    "\n",
    "- Essencially, we are talking about a text clustering problem\n",
    "    - Documents are words clustered simultaneously\n",
    "    \n",
    "\n",
    "- Different topic modeling approaches are available:\n",
    "    - Probabilistic Latent Semantic Analysis (PLSA) \n",
    "    - **Latent Dirichlet Allocation (LDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Models and Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "\n",
    "- Generative models for a document d\n",
    "    - Choose length of a the document `d`\n",
    "    - Choose a mixture of topics for the document `d`\n",
    "    - Use a topic's multinomial distribution to output words to fill that topic's quota\n",
    "    \n",
    "    \n",
    "    \n",
    "### Topic Modeling in Practice\n",
    "\n",
    "- How many Topics?\n",
    "    - Finding or even guessing the number of topics inside a document is a hard task\n",
    "\n",
    "\n",
    "- Interpreting topics\n",
    "    - Topics are just word distributions\n",
    "    - Making sense of words / generationg labels is subjective (*computer science, data science* may be seen as similar tags) \n",
    "    \n",
    "    \n",
    "    \n",
    "### Topic Modeling - Summary\n",
    "\n",
    "- Great tool for exploratory text analysis\n",
    "    - What are the documents (tweets, reviews, news, articles) about?\n",
    "\n",
    "\n",
    "- Many tools are available to do it effortless by using Python\n",
    "\n",
    "\n",
    "\n",
    "### Working with LDA in Python\n",
    "\n",
    "- There are many packages available, such as *gensim and lda*\n",
    "\n",
    "\n",
    "- Pre-processing text steps:\n",
    "    - Tokenize the text in sencentes and words, then normalize (lowercase) the tokens\n",
    "    - Remove the Stop-Words such as the, is, ...\n",
    "    - Stemming and Lemmatization\n",
    "    \n",
    "\n",
    "- Convert tokenized documents to a document - term matrix\n",
    "\n",
    "- Build LDA models on the doc-term matrix\n",
    "\n",
    "\n",
    "- `Doc_set`: set of pre-processed text documents\n",
    "\n",
    "```python\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "\n",
    "dictionary = corpora.Dictionary(doc_set)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in doc_set]\n",
    "lda_model = gensim.ldamodel.LdaModel(corpus, num_topics=4, id2word=dictionary, passes=50)\n",
    "\n",
    "print(lda_model.print_topics(num_topics=4, num_words=5))```\n",
    "\n",
    "\n",
    "- The lda_model can also be used to find topic distribution of the documents\n",
    "\n",
    "\n",
    "\n",
    "### Take Home Concepts\n",
    "\n",
    "- Topic modeling is an exploratory tool frequently used for text mining\n",
    "\n",
    "- Linear Disrichlet Allocation is a generative model used extensivly for modeling large text corpora\n",
    "\n",
    "- LDA can also be used as a feature selection technique for text classification and other tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information is Hidden in Free-Text and Information Extraction\n",
    "\n",
    "- Most traditional transactional information is in a structured format\n",
    "\n",
    "\n",
    "- Abundance of unstructured data, freeform text\n",
    "    - 3 most common type of unstructured data: Image, Sound, Text\n",
    "\n",
    "\n",
    "- How to convert unstrctured text to a structured form?\n",
    "\n",
    "\n",
    "- The GOAL is to identify and extract the fields of interest from the free and unstructured text\n",
    "     - For example: Imagine we are looking at an internet article of Lung Cancer, so the most common information that would be of interest to extract from the article would be:\n",
    "         - Erbitux helps treat lung cancer\n",
    "         - Author: Charlene Laino\n",
    "         - Reviewers: Louise Chang, MD\n",
    "         - Date: September 23, 2009\n",
    "         - Location: Berlin\n",
    "         - ...\n",
    "         \n",
    "         \n",
    "\n",
    "### Fields of Interest\n",
    "\n",
    "- Named entities\n",
    "    - **<font color='red'>[NEWS]</font>** Peoples, Places, Dates, ...\n",
    "    - **<font color='red'>[FINANCE]</font>** Companies, Stocks, Money, ...\n",
    "    - **<font color='red'>[MEDICINE]</font>** Diseases, Drugs, Procedures, ...\n",
    "    \n",
    "    \n",
    "- Relations\n",
    "    - What happened to *who, when, where, ...*\n",
    "    \n",
    "    \n",
    "    \n",
    "### Named Entity Recognition\n",
    "\n",
    "- **<font color='red'>Named Entities</font> :** Noun phrases that are of specific type and refer to specific individuals, places, organizations\n",
    "\n",
    "\n",
    "- **<font color='red'>Named Entities Recognition</font> :** Technique(s) to identify all mentionsof pre-defined named entities in text:\n",
    "    - Identify the mention / phrase: Boundary detection\n",
    "    - Identify the type: *Tagging* / classification\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### Approaches to Identify Named Entities\n",
    "\n",
    "- Depends on kinds of entities that need to be identified\n",
    "\n",
    "- For well-formatted fields like dates, phone numbers it's recommended to use Regex (recall Week 1 Assignment)\n",
    "\n",
    "- For other fields: Typically a machine learning algorithm (recall Week 3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Person, Organization, Location / GPE\n",
    "\n",
    "\n",
    "- Standard NER task in NLP reserch community\n",
    "\n",
    "\n",
    "\n",
    "- Typically a four-class model\n",
    "    - PER (person)\n",
    "    - ORG (organization)\n",
    "    - LOC/GPE (location)\n",
    "    - Other / Outside (any other class)\n",
    "    \n",
    "    \n",
    "    \n",
    "### Question Answering\n",
    "\n",
    "\n",
    "- Given a question, find the most appropiate answer from the text\n",
    "    - What does Erbitux treat?\n",
    "    - Who gave Anita the rose?\n",
    "    \n",
    "    \n",
    "    \n",
    "- Builds on named entity recognition, relation extracction, and co-reference resolution\n",
    "\n",
    "\n",
    "\n",
    "### Take Home Concepts\n",
    "\n",
    "- Information Extraction is important for natural language understanding and making sense of textual data\n",
    "\n",
    "- Named Entity Recognition is a key building block to address many advanced NLP tasks\n",
    "\n",
    "- Named Entity Recognition systems extensively deploy supervised machine learning and text mining techniques disscued in this course\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
