{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48770f8b5f5d3062d3badd51fcafc401",
     "grade": false,
     "grade_id": "cell-a6c4f74309fc2379",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 4\n",
    "## Description\n",
    "In this assignment you must read in a file of metropolitan regions and associated sports teams from [assets/wikipedia_data.html](assets/wikipedia_data.html) and answer some questions about each metropolitan region. Each of these regions may have one or more teams from the \"Big 4\": NFL (football, in [assets/nfl.csv](assets/nfl.csv)), MLB (baseball, in [assets/mlb.csv](assets/mlb.csv)), NBA (basketball, in [assets/nba.csv](assets/nba.csv) or NHL (hockey, in [assets/nhl.csv](assets/nhl.csv)). Please keep in mind that all questions are from the perspective of the metropolitan region, and that this file is the \"source of authority\" for the location of a given sports team. Thus teams which are commonly known by a different area (e.g. \"Oakland Raiders\") need to be mapped into the metropolitan region given (e.g. San Francisco Bay Area). This will require some human data understanding outside of the data you've been given (e.g. you will have to hand-code some names, and might need to google to find out where teams are)!\n",
    "\n",
    "For each sport I would like you to answer the question: **what is the win/loss ratio's correlation with the population of the city it is in?** Win/Loss ratio refers to the number of wins over the number of wins plus the number of losses. Remember that to calculate the correlation with [`pearsonr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html), so you are going to send in two ordered lists of values, the populations from the wikipedia_data.html file and the win/loss ratio for a given sport in the same order. Average the win/loss ratios for those cities which have multiple teams of a single sport. Each sport is worth an equal amount in this assignment (20%\\*4=80%) of the grade for this assignment. You should only use data **from year 2018** for your analysis -- this is important!\n",
    "\n",
    "## Notes\n",
    "\n",
    "1. Do not include data about the MLS or CFL in any of the work you are doing, we're only interested in the Big 4 in this assignment.\n",
    "2. I highly suggest that you first tackle the four correlation questions in order, as they are all similar and worth the majority of grades for this assignment. This is by design!\n",
    "3. It's fair game to talk with peers about high level strategy as well as the relationship between metropolitan areas and sports teams. However, do not post code solving aspects of the assignment (including such as dictionaries mapping areas to teams, or regexes which will clean up names).\n",
    "4. There may be more teams than the assert statements test, remember to collapse multiple teams in one city into a single value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "369ff9ecf0ee04640574205cbc697f94",
     "grade": false,
     "grade_id": "cell-712b2b5da63d4505",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1\n",
    "For this question, calculate the win/loss ratio's correlation with the population of the city it is in for the **NHL** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1cac4803b02502929f5b1612d48db2b5",
     "grade": false,
     "grade_id": "cell-69b16e4386e58030",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "\n",
    "# Functions\n",
    "def remove_square_brackets(data):\n",
    "# Search for everything between the square brackets [] and replace it with '' if any, otherwise, return the string\n",
    "    if re.search(\"\\[(.*?)\\]\", data) is None:\n",
    "        return data\n",
    "    else:\n",
    "        return data.replace(re.search(\"\\[(.*?)\\]\", data).group(), '')\n",
    "\n",
    "    \n",
    "def remove_asterisk(data):\n",
    "    # Search for * at the end and remove it if any, otherwise, return the string\n",
    "    char = '*'\n",
    "    if char == data[-1]:\n",
    "        return data.strip(char)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_region(team_last_word):\n",
    "    # Search for the team last name in all the teams\n",
    "    for teams in list(nhl_city_population['NHL'].values):\n",
    "        # If the team is found, return the Metropolitan area\n",
    "        if team_last_word in teams:\n",
    "            return nhl_city_population[nhl_city_population['NHL'] == teams].index[0]\n",
    "\n",
    "\n",
    "def nhl_return_merged_data():\n",
    "    return merged_df_nhl\n",
    "\n",
    "\n",
    "# Variables\n",
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "        \n",
    "# Data cleaning in the cities DataFrame\n",
    "cities['NHL'] = cities['NHL'].apply(lambda x: remove_square_brackets(x))\n",
    "# Select Year = 2018 and drop irrelevant rows\n",
    "nhl_df = nhl_df[nhl_df['year'] == 2018].drop([0, 9, 18, 26], axis=0)\n",
    "\n",
    "# Select the required columns and create nhl_city_population DataFrame and clean the data\n",
    "nhl_city_population = cities[['Metropolitan area', 'Population (2016 est.)[8]', 'NHL']]\n",
    "nhl_city_population.set_index('Metropolitan area', inplace=True)\n",
    "nhl_city_population['NHL'] = nhl_city_population['NHL'].apply(lambda x: remove_square_brackets(x))\n",
    "nhl_city_population['NHL'] = nhl_city_population['NHL'].replace(to_replace=['â€”', ''], value=np.nan)\n",
    "nhl_city_population.dropna(inplace=True, axis=0)\n",
    "\n",
    "# Clean the data and split the team column to extract the region of the team \n",
    "nhl_df['team'] = nhl_df['team'].apply(lambda x: remove_asterisk(x))\n",
    "nhl_df['team_last_word'] = nhl_df['team'].apply(lambda x: x.split(' ')[-1].strip())\n",
    "nhl_df['Region'] = nhl_df['team_last_word'].apply(lambda x: extract_region(x))\n",
    "\n",
    "# Transform the Win and Loss Columns from object to numeric\n",
    "nhl_df['W'] = nhl_df['W'].astype(int)\n",
    "nhl_df['L'] = nhl_df['L'].astype(int)\n",
    "\n",
    "# Estimate the Win/(Win+Loss) Ratio column\n",
    "nhl_df['Win/Loss Ratio'] = nhl_df['W'] / (nhl_df['W'] + nhl_df['L'])\n",
    "nhl_df.set_index('Region', inplace=True)\n",
    "\n",
    "# groupby() the region column and estimate the mean ratio per region\n",
    "report_list = []\n",
    "for group, frame in nhl_df.groupby(level=nhl_df.index.name):\n",
    "    report_list.append({'Region': group, 'Win-Loss Ratio': frame['Win/Loss Ratio'].mean()})\n",
    "\n",
    "# Create DataFrame from the report\n",
    "report_df = pd.DataFrame(report_list).set_index('Region')\n",
    "\n",
    "# Merge report_df and nhl_city_population DataFrames\n",
    "merged_df_nhl = pd.merge(report_df, nhl_city_population, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Transform Population Columns from object to numeric\n",
    "merged_df_nhl['Population (2016 est.)[8]'] = merged_df_nhl['Population (2016 est.)[8]'].astype(int)\n",
    "\n",
    "# Create the lists of the population and the ratio to estimate the correlation and p-value\n",
    "population_by_region_nhl = list(merged_df_nhl['Population (2016 est.)[8]'].values)\n",
    "win_loss_by_region_nhl = list(merged_df_nhl['Win-Loss Ratio'].values)\n",
    "\n",
    "# ANSWER FUNCTION 1\n",
    "def nhl_correlation(): \n",
    "    global population_by_region_nhl\n",
    "    global win_loss_by_region_nhl\n",
    "    \n",
    "    assert len(population_by_region_nhl) == len(win_loss_by_region_nhl), \"Q1: Your lists must be the same length\"\n",
    "    assert len(population_by_region_nhl) == 28, \"Q1: There should be 28 teams being analysed for NHL\"\n",
    "    \n",
    "    corr, pval = stats.pearsonr(population_by_region_nhl, win_loss_by_region_nhl)\n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012486162921209907"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhl_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHL - National Hockey League\n",
    "\n",
    "Variable Description\n",
    "\n",
    "- **GP**: Number of games played\n",
    "- **W**: Number of games won\n",
    "- **L**: Number of Lost\n",
    "- **OL**: How many games were lost in overtime or in a shootout\n",
    "- **PTS**: Total points\n",
    "- **PTS%**: Percentage of total points earned from the points available\n",
    "- **GF**: Number of goals scored by the team\n",
    "- **GA**: Number of goals scored against the team\n",
    "- **SRS**: Simple Rating System; a rating that takes into account average goal differential and strength of schedule. The rating is denominated in goals above/below average, where zero is average.\n",
    "- **SOS**: Strength of Schedule; a rating of strength of schedule. The rating is denominated in goals above/below average, where zero is average. \n",
    "- **RPt%**: \"Real\" Points percentage. It counts 0 points for an OT loss, and any shootout game as a tie (1 point). In other words, the pre-2000 situation.\n",
    "- **ROW**: Team's total number of regulation and overtime wins.\n",
    "- **Year**: Year that the season occurred. Since the NHL season is split over two calendar years, the year given is the last year for that season. For example, the year for the 2008-09 season would be 2009.\n",
    "- **League**: League of the Big 4 sport.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_square_brackets(data):\n",
    "    # Search for everything between the square brackets [] and replace it with '' if any, otherwise, return the string\n",
    "    if re.search(\"\\[(.*?)\\]\", data) is None:\n",
    "        return data\n",
    "    else:\n",
    "        return data.replace(re.search(\"\\[(.*?)\\]\", data).group(), '')\n",
    "    \n",
    "    \n",
    "def remove_asterisk(data):\n",
    "    # Search for * at the end and remove it if any, otherwise, return the string\n",
    "    char = \"*\"\n",
    "    if char == data[-1]:\n",
    "        return data.strip(char)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_region(team_last_word):\n",
    "    # Search for the team last name in all the teams\n",
    "    for teams in list(nhl_city_population['NHL'].values):\n",
    "        # If the team is found, return the Metropolitan area\n",
    "        if team_last_word in teams:\n",
    "            return nhl_city_population[nhl_city_population['NHL'] == teams].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0 9 18 26] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-69c54c0f9862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mremove_square_brackets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Select Year = 2018 and drop irrelevant rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnhl_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnhl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnhl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2018\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnhl_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4095\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4096\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4097\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4098\u001b[0m         )\n\u001b[1;32m   4099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3913\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3914\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3915\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3964\u001b[0m                 \u001b[0mlabels_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3965\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabels_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3966\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3968\u001b[0m             \u001b[0mslicer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[0 9 18 26] not found in axis'"
     ]
    }
   ],
   "source": [
    "# Data cleaning in the cities DataFrame\n",
    "cities['NHL'].apply(lambda x: remove_square_brackets(x))\n",
    "# Select Year = 2018 and drop irrelevant rows\n",
    "nhl_df = nhl_df[nhl_df['year'] == 2018].drop([0, 9, 18, 26], axis=0)\n",
    "nhl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-95a88e7d0960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnhl_city_population\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Metropolitan area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Population (2016 est.)[8]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Metropolitan area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mremove_square_brackets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'â€”'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4036\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4037\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4038\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-95a88e7d0960>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnhl_city_population\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Metropolitan area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Population (2016 est.)[8]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Metropolitan area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mremove_square_brackets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NHL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'â€”'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnhl_city_population\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-324d126f6a8d>\u001b[0m in \u001b[0;36mremove_square_brackets\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_square_brackets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Search for everything between the square brackets [] and replace it with '' if any, otherwise, return the string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\[(.*?)\\]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    182\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Select the required columns and create nhl_city_population DataFrame and clean the data\n",
    "nhl_city_population = cities[['Metropolitan area', 'Population (2016 est.)[8]', 'NHL']]\n",
    "nhl_city_population.set_index('Metropolitan area', inplace=True)\n",
    "nhl_city_population['NHL'] = nhl_city_population['NHL'].apply(lambda x: remove_square_brackets(x))\n",
    "nhl_city_population['NHL'] = nhl_city_population['NHL'].replace(to_replace=['â€”', ''], value=np.nan)\n",
    "nhl_city_population.dropna(inplace=True, axis=0)\n",
    "nhl_city_population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data and split the team column to extract the region of the team \n",
    "nhl_df['team'] = nhl_df['team'].apply(lambda x: remove_asterisk(x))\n",
    "nhl_df['team_last_word'] = nhl_df['team'].apply(lambda x: x.split(' ')[-1].strip())\n",
    "nhl_df['Region'] = nhl_df['team_last_word'].apply(lambda x: extract_region(x))\n",
    "\n",
    "# Transform the Win and Loss Columns from object to numeric\n",
    "nhl_df['W'] = nhl_df['W'].astype(int)\n",
    "nhl_df['L'] = nhl_df['L'].astype(int)\n",
    "\n",
    "# Estimate the Win/(Win+Loss) Ratio column\n",
    "nhl_df['Win/Loss Ratio'] = nhl_df['W'] / (nhl_df['W'] + nhl_df['L'])\n",
    "nhl_df.set_index('Region', inplace=True)\n",
    "nhl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby() the region column and estimate the mean ratio per region\n",
    "report_list = []\n",
    "for group, frame in nhl_df.groupby(level=nhl_df.index.name):\n",
    "    report_list.append({'Region': group, 'Win-Loss Ratio': frame['Win/Loss Ratio'].mean()})\n",
    "\n",
    "# Create DataFrame from the report\n",
    "report_df = pd.DataFrame(report_list).set_index('Region')\n",
    "\n",
    "# Merge report_df and nhl_city_population DataFrames\n",
    "merged_df = pd.merge(report_df, nhl_city_population, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Population Columns from object to numeric\n",
    "merged_df['Population (2016 est.)[8]'] = merged_df['Population (2016 est.)[8]'].astype(int)\n",
    "\n",
    "# Create the lists of the population and the ratio to estimate the correlation and p-value\n",
    "population_by_region = list(merged_df['Population (2016 est.)[8]'].values)\n",
    "win_loss_by_region = list(merged_df['Win-Loss Ratio'].values)\n",
    "\n",
    "# Estimate the correlation and the p-value using scipy.stats\n",
    "corr, pval = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "print('corr:', round(corr, 1))\n",
    "print('p-value:', pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "52a581df513c71153e105b93764cda4b",
     "grade": true,
     "grade_id": "cell-ebe0b2dfe1067e63",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "988912cae4968d81473f46d783e79c16",
     "grade": false,
     "grade_id": "cell-cb964e690298b71d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "For this question, calculate the win/loss ratio's correlation with the population of the city it is in for the **NBA** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9394222aafc8ccab0a228098ba0d6010",
     "grade": false,
     "grade_id": "cell-5a5f21279e3d3572",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "nba_df=pd.read_csv(\"assets/nba.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "\n",
    "def extract_region_two(team_last_word):\n",
    "    # Search for the team last name in all the teams\n",
    "    for teams in list(nba_city_population['NBA'].values):\n",
    "        # If the team is found, return the Metropolitan area (index of the DataFrame)\n",
    "        if team_last_word in teams:\n",
    "            return nba_city_population[nba_city_population['NBA'] == teams].index[0]\n",
    "\n",
    "        \n",
    "def nba_return_merged_data():\n",
    "    return merged_df_nba        \n",
    "\n",
    "\n",
    "# NBA_DF\n",
    "# Remove not usefull rows that have the division information\n",
    "nba_df = nba_df[~nba_df['team'].str.contains('Division')]\n",
    "\n",
    "# Split the NBA team's columns and get rid of not usfull data\n",
    "nba_df['team'] = nba_df['team'].apply(lambda x: x.split('\\xa0(')[0])\n",
    "\n",
    "# Remove * character from the end of the title column data if any\n",
    "nba_df['team'] = nba_df['team'].apply(lambda x: remove_asterisk(x).strip())\n",
    "\n",
    "# Select only the year = 2018\n",
    "nba_df = nba_df[nba_df['year'] == 2018]\n",
    "\n",
    "# Transform the Win and Loss Columns from object to numeric\n",
    "nba_df['W'] = nba_df['W'].astype(int)\n",
    "nba_df['L'] = nba_df['L'].astype(int)\n",
    "\n",
    "# Estimate the Win/(Win + Loss) Ratio Column\n",
    "nba_df['Win/Loss Ratio'] = nba_df['W'] / (nba_df['W'] + nba_df['L'])\n",
    "\n",
    "# Data cleaning in the cities DataFrame\n",
    "cities['NBA'].apply(lambda x: remove_square_brackets(x))\n",
    "\n",
    "# Select the required columns and create nhl_city_population DataFrame and clean the data\n",
    "nba_city_population = cities[['Metropolitan area', 'Population (2016 est.)[8]', 'NBA']]\n",
    "nba_city_population.set_index('Metropolitan area', inplace=True)\n",
    "nba_city_population['NBA'] = nba_city_population['NBA'].apply(lambda x: remove_square_brackets(x))\n",
    "nba_city_population['NBA'] = nba_city_population['NBA'].replace(to_replace=['â€”', ''], value=np.nan)\n",
    "nba_city_population.dropna(inplace=True, axis=0)\n",
    "\n",
    "# Extract the team last name from the title column\n",
    "nba_df['team_last_word'] = nba_df['team'].apply(lambda x: x.split(' ')[-1].strip())\n",
    "\n",
    "# Create the region data from the title column\n",
    "nba_df['Region'] = nba_df['team_last_word'].apply(lambda x: extract_region_two(x))\n",
    "\n",
    "# groupby() the region column and estimate the mean ratio per region\n",
    "report_list = []\n",
    "\n",
    "for group, frame in nba_df.groupby(by='Region'):\n",
    "    report_list.append({'Region': group, 'Win-Loss Ratio': frame['Win/Loss Ratio'].mean()})\n",
    "\n",
    "# Create DataFrame from the report\n",
    "report_df = pd.DataFrame(report_list).set_index('Region')\n",
    "\n",
    "# Merge report_df and nhl_city_population DataFrames\n",
    "merged_df_nba = pd.merge(report_df, nba_city_population, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Transform Population Columns from object to numeric\n",
    "merged_df_nba['Population (2016 est.)[8]'] = merged_df_nba['Population (2016 est.)[8]'].astype(int)\n",
    "\n",
    "# Create the lists of the population and the ratio to estimate the correlation and p-value\n",
    "population_by_region_nba = list(merged_df_nba['Population (2016 est.)[8]'].values)\n",
    "win_loss_by_region_nba = list(merged_df_nba['Win-Loss Ratio'].values)\n",
    "\n",
    "\n",
    "def nba_correlation():\n",
    "    # YOUR CODE HERE\n",
    "    global population_by_region_nba\n",
    "    global win_loss_by_region_nba\n",
    "    \n",
    "    assert len(population_by_region_nba) == len(win_loss_by_region_nba), \"Q2: Your lists must be the same length\"\n",
    "    assert len(population_by_region_nba) == 28, \"Q2: There should be 28 teams being analysed for NBA\"\n",
    "\n",
    "    corr, pval = stats.pearsonr(population_by_region_nba, win_loss_by_region_nba)\n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17657160252844617"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBA_DF\n",
    "# Remove not usefull rows that have the division information\n",
    "nba_df = nba_df[~nba_df['team'].str.contains('Division')]\n",
    "\n",
    "# Split the NBA team's columns and get rid of not usfull data\n",
    "nba_df['team'] = nba_df['team'].apply(lambda x: x.split('\\xa0(')[0])\n",
    "\n",
    "# Remove * character from the end of the title column data if any\n",
    "nba_df['team'] = nba_df['team'].apply(lambda x: remove_asterisk(x).strip())\n",
    "\n",
    "# Select only the year = 2018\n",
    "nba_df = nba_df[nba_df['year'] == 2018]\n",
    "\n",
    "# Transform the Win and Loss Columns from object to numeric\n",
    "nba_df['W'] = nba_df['W'].astype(int)\n",
    "nba_df['L'] = nba_df['L'].astype(int)\n",
    "\n",
    "# Estimate the Win/(Win + Loss) Ratio Column\n",
    "nba_df['Win/Loss Ratio'] = nba_df['W'] / (nba_df['W'] + nba_df['L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning in the cities DataFrame\n",
    "cities['NBA'].apply(lambda x: remove_square_brackets(x))\n",
    "\n",
    "# Select the required columns and create nhl_city_population DataFrame and clean the data\n",
    "nba_city_population = cities[['Metropolitan area', 'Population (2016 est.)[8]', 'NBA']]\n",
    "nba_city_population.set_index('Metropolitan area', inplace=True)\n",
    "nba_city_population['NBA'] = nba_city_population['NBA'].apply(lambda x: remove_square_brackets(x))\n",
    "nba_city_population['NBA'] = nba_city_population['NBA'].replace(to_replace=['â€”', ''], value=np.nan)\n",
    "nba_city_population.dropna(inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the team last name from the title column\n",
    "nba_df['team_last_word'] = nba_df['team'].apply(lambda x: x.split(' ')[-1].strip())\n",
    "\n",
    "def extract_region_two(team_last_word):\n",
    "    # Search for the team last name in all the teams\n",
    "    for teams in list(nba_city_population['NBA'].values):\n",
    "        # If the team is found, return the Metropolitan area (index of the DataFrame)\n",
    "        if team_last_word in teams:\n",
    "            return nba_city_population[nba_city_population['NBA'] == teams].index[0]\n",
    "\n",
    "# Create the region data from the title column\n",
    "nba_df['Region'] = nba_df['team_last_word'].apply(lambda x: extract_region_two(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby() the region column and estimate the mean ratio per region\n",
    "report_list = []\n",
    "\n",
    "for group, frame in nba_df.groupby(by='Region'):\n",
    "    report_list.append({'Region': group, 'Win-Loss Ratio': frame['Win/Loss Ratio'].mean()})\n",
    "\n",
    "# Create DataFrame from the report\n",
    "report_df = pd.DataFrame(report_list).set_index('Region')\n",
    "\n",
    "# Merge report_df and nhl_city_population DataFrames\n",
    "merged_df = pd.merge(report_df, nba_city_population, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Transform Population Columns from object to numeric\n",
    "merged_df['Population (2016 est.)[8]'] = merged_df['Population (2016 est.)[8]'].astype(int)\n",
    "\n",
    "# Create the lists of the population and the ratio to estimate the correlation and p-value\n",
    "population_by_region = list(merged_df['Population (2016 est.)[8]'].values)\n",
    "win_loss_by_region = list(merged_df['Win-Loss Ratio'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the correlation and the p-value using scipy.stats\n",
    "corr, pval = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "print('corr:', corr)\n",
    "print('p-value:', pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bbdeb8eb22f525a34c10dc8798324e42",
     "grade": true,
     "grade_id": "cell-e573b2b4a282b470",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a1a5809f675ca033086422007cd73bd",
     "grade": false,
     "grade_id": "cell-96e15e4335df78f4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 3\n",
    "For this question, calculate the win/loss ratio's correlation with the population of the city it is in for the **MLB** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "27e8c0da6c9fa0dffc10488314335b6c",
     "grade": false,
     "grade_id": "cell-33b00fc3f3467b0c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "\n",
    "# Functions\n",
    "def extract_last_words_mlb(data):\n",
    "    boston_char = 'Boston'\n",
    "    chicago_char = 'Chicago'\n",
    "    \n",
    "    if boston_char in data.split(' ')[0]:\n",
    "        return 'Red Sox'\n",
    "    elif chicago_char in data.split(' ')[0]:\n",
    "        return 'White Sox'\n",
    "    \n",
    "    return data.split(' ')[-1]\n",
    "\n",
    "\n",
    "def extract_region_three(team_last_word):\n",
    "    # Search for the team last name in all the teams\n",
    "    for teams in list(mlb_city_population['MLB'].values):\n",
    "        # If the team is found, return the Metropolitan area\n",
    "        if team_last_word in teams:\n",
    "            return mlb_city_population[mlb_city_population['MLB'] == teams].index[0]\n",
    "\n",
    "        \n",
    "def mlb_return_merged_data():\n",
    "    return merged_df_mlb\n",
    "\n",
    "\n",
    "######################\n",
    "# Dataframes\n",
    "mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "# Select only the year = 2018\n",
    "mlb_df = mlb_df[mlb_df['year'] == 2018]\n",
    "\n",
    "# Estimate the Win/(Win + Loss) Ratio Column\n",
    "mlb_df['Win/Loss Ratio'] = mlb_df['W'] / (mlb_df['W'] + mlb_df['L'])\n",
    "\n",
    "# Data cleaning in the cities DataFrame\n",
    "cities['MLB'] = cities['MLB'].apply(lambda x: remove_square_brackets(x))\n",
    "cities.replace(to_replace=['â€”', ''], value=np.nan, inplace=True)\n",
    "\n",
    "# Select the required columns and create nhl_city_population DataFrame and clean the data\n",
    "mlb_city_population = cities[['Metropolitan area', 'Population (2016 est.)[8]', 'MLB']]\n",
    "mlb_city_population.set_index('Metropolitan area', inplace=True)\n",
    "mlb_city_population.dropna(inplace=True, axis=0)\n",
    "\n",
    "# Extract the team name or last name from the team column\n",
    "mlb_df['team_last_name'] = mlb_df['team'].apply(lambda x: extract_last_words_mlb(x))\n",
    "\n",
    "# Create the region data from the title column and set it as the index of the df\n",
    "mlb_df['Region'] = mlb_df['team_last_name'].apply(lambda x: extract_region_three(x))\n",
    "mlb_df.set_index('Region', inplace=True)\n",
    "\n",
    "# groupby() the region column and estimate the mean ratio per region\n",
    "report_list = []\n",
    "\n",
    "for group, frame in mlb_df.groupby(by='Region'):\n",
    "    report_list.append({'Region': group, 'Win-Loss Ratio': frame['Win/Loss Ratio'].mean()})\n",
    "\n",
    "# Create DataFrame from the report\n",
    "report_df = pd.DataFrame(report_list).set_index('Region')\n",
    "\n",
    "# Merge report_df and nhl_city_population DataFrames\n",
    "merged_df_mlb = pd.merge(report_df, mlb_city_population, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Transform Population Columns from object to numeric\n",
    "merged_df_mlb['Population (2016 est.)[8]'] = merged_df_mlb['Population (2016 est.)[8]'].astype(int)\n",
    "\n",
    "# Create the lists of the population and the ratio to estimate the correlation and p-value\n",
    "population_by_region_mlb = list(merged_df_mlb['Population (2016 est.)[8]'].values)\n",
    "win_loss_by_region_mlb = list(merged_df_mlb['Win-Loss Ratio'].values)\n",
    "\n",
    "\n",
    "def mlb_correlation(): \n",
    "    # YOUR CODE HERE\n",
    "    global population_by_region_mlb\n",
    "    global win_loss_by_region_mlb\n",
    "\n",
    "    assert len(population_by_region_mlb) == len(win_loss_by_region_mlb), \"Q3: Your lists must be the same length\"\n",
    "    assert len(population_by_region_mlb) == 26, \"Q3: There should be 26 teams being analysed for MLB\"\n",
    "\n",
    "    corr, pval = stats.pearsonr(population_by_region_mlb, win_loss_by_region_mlb)\n",
    "    \n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15027698302669307"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     team    W    L   W-L%    GB  year League  Win/Loss Ratio  \\\n",
      "0          Boston Red Sox  108   54  0.667    --  2018    MLB        0.666667   \n",
      "1        New York Yankees  100   62  0.617   8.0  2018    MLB        0.617284   \n",
      "2          Tampa Bay Rays   90   72  0.556  18.0  2018    MLB        0.555556   \n",
      "3       Toronto Blue Jays   73   89  0.451  35.0  2018    MLB        0.450617   \n",
      "4       Baltimore Orioles   47  115  0.290  61.0  2018    MLB        0.290123   \n",
      "5       Cleveland Indians   91   71  0.562    --  2018    MLB        0.561728   \n",
      "6         Minnesota Twins   78   84  0.481  13.0  2018    MLB        0.481481   \n",
      "7          Detroit Tigers   64   98  0.395  27.0  2018    MLB        0.395062   \n",
      "8       Chicago White Sox   62  100  0.383  29.0  2018    MLB        0.382716   \n",
      "9      Kansas City Royals   58  104  0.358  33.0  2018    MLB        0.358025   \n",
      "10         Houston Astros  103   59  0.636    --  2018    MLB        0.635802   \n",
      "11      Oakland Athletics   97   65  0.599   6.0  2018    MLB        0.598765   \n",
      "12       Seattle Mariners   89   73  0.549  14.0  2018    MLB        0.549383   \n",
      "13     Los Angeles Angels   80   82  0.494  23.0  2018    MLB        0.493827   \n",
      "14          Texas Rangers   67   95  0.414  36.0  2018    MLB        0.413580   \n",
      "15         Atlanta Braves   90   72  0.556    --  2018    MLB        0.555556   \n",
      "16   Washington Nationals   82   80  0.506   8.0  2018    MLB        0.506173   \n",
      "17  Philadelphia Phillies   80   82  0.494  10.0  2018    MLB        0.493827   \n",
      "18          New York Mets   77   85  0.475  13.0  2018    MLB        0.475309   \n",
      "19          Miami Marlins   63   98  0.391  26.5  2018    MLB        0.391304   \n",
      "20      Milwaukee Brewers   96   67  0.589    --  2018    MLB        0.588957   \n",
      "21           Chicago Cubs   95   68  0.583   1.0  2018    MLB        0.582822   \n",
      "22    St. Louis Cardinals   88   74  0.543   7.5  2018    MLB        0.543210   \n",
      "23     Pittsburgh Pirates   82   79  0.509  13.0  2018    MLB        0.509317   \n",
      "24        Cincinnati Reds   67   95  0.414  28.5  2018    MLB        0.413580   \n",
      "25    Los Angeles Dodgers   92   71  0.564    --  2018    MLB        0.564417   \n",
      "26       Colorado Rockies   91   72  0.558   1.0  2018    MLB        0.558282   \n",
      "27   Arizona Diamondbacks   82   80  0.506   9.5  2018    MLB        0.506173   \n",
      "28   San Francisco Giants   73   89  0.451  18.5  2018    MLB        0.450617   \n",
      "29       San Diego Padres   66   96  0.407  25.5  2018    MLB        0.407407   \n",
      "\n",
      "   team_last_name  \n",
      "0         Red Sox  \n",
      "1         Yankees  \n",
      "2            Rays  \n",
      "3            Jays  \n",
      "4         Orioles  \n",
      "5         Indians  \n",
      "6           Twins  \n",
      "7          Tigers  \n",
      "8       White Sox  \n",
      "9          Royals  \n",
      "10         Astros  \n",
      "11      Athletics  \n",
      "12       Mariners  \n",
      "13         Angels  \n",
      "14        Rangers  \n",
      "15         Braves  \n",
      "16      Nationals  \n",
      "17       Phillies  \n",
      "18           Mets  \n",
      "19        Marlins  \n",
      "20        Brewers  \n",
      "21      White Sox  \n",
      "22      Cardinals  \n",
      "23        Pirates  \n",
      "24           Reds  \n",
      "25        Dodgers  \n",
      "26        Rockies  \n",
      "27   Diamondbacks  \n",
      "28         Giants  \n",
      "29         Padres  \n"
     ]
    }
   ],
   "source": [
    "# MLB_DF\n",
    "\n",
    "mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "# Select only the year = 2018\n",
    "mlb_df = mlb_df[mlb_df['year'] == 2018]\n",
    "\n",
    "# Estimate the Win/(Win + Loss) Ratio Column\n",
    "mlb_df['Win/Loss Ratio'] = mlb_df['W'] / (mlb_df['W'] + mlb_df['L'])\n",
    "\n",
    "# Data cleaning in the cities DataFrame\n",
    "cities['MLB'] = cities['MLB'].apply(lambda x: remove_square_brackets(x))\n",
    "cities.replace(to_replace=['â€”', ''], value=np.nan, inplace=True)\n",
    "\n",
    "# Select the required columns and create nhl_city_population DataFrame and clean the data\n",
    "mlb_city_population = cities[['Metropolitan area', 'Population (2016 est.)[8]', 'MLB']]\n",
    "mlb_city_population.set_index('Metropolitan area', inplace=True)\n",
    "mlb_city_population.dropna(inplace=True, axis=0)\n",
    "\n",
    "\n",
    "def extract_last_words_mlb(data):\n",
    "    boston_char = 'Boston'\n",
    "    chicago_char = 'Chicago'\n",
    "    if boston_char in data.split(' ')[0]:\n",
    "        return 'Red Sox'\n",
    "    elif chicago_char in data.split(' ')[0]:\n",
    "        return 'White Sox'\n",
    "    \n",
    "    return data.split(' ')[-1]\n",
    "\n",
    "\n",
    "# Extract the team name or last name from the team column\n",
    "mlb_df['team_last_name'] = mlb_df['team'].apply(lambda x: extract_last_words_mlb(x))\n",
    "\n",
    "#print('DF length: ', len(mlb_city_population))\n",
    "#print(mlb_city_population)\n",
    "#print()\n",
    "#print('DF length: ', len(mlb_df))\n",
    "print(mlb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region_three(team_last_word):\n",
    "    # Search for the team last name in all the teams\n",
    "    for teams in list(mlb_city_population['MLB'].values):\n",
    "        # If the team is found, return the Metropolitan area\n",
    "        if team_last_word in teams:\n",
    "            return mlb_city_population[mlb_city_population['MLB'] == teams].index[0]\n",
    "\n",
    "        \n",
    "# Create the region data from the title column and set it as the index of the df\n",
    "mlb_df['Region'] = mlb_df['team_last_name'].apply(lambda x: extract_region_three(x))\n",
    "mlb_df.set_index('Region', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby() the region column and estimate the mean ratio per region\n",
    "report_list = []\n",
    "\n",
    "for group, frame in mlb_df.groupby(by='Region'):\n",
    "    report_list.append({'Region': group, 'Win-Loss Ratio': frame['Win/Loss Ratio'].mean()})\n",
    "\n",
    "# Create DataFrame from the report\n",
    "report_df = pd.DataFrame(report_list).set_index('Region')\n",
    "\n",
    "# Merge report_df and nhl_city_population DataFrames\n",
    "merged_df = pd.merge(report_df, mlb_city_population, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Transform Population Columns from object to numeric\n",
    "merged_df['Population (2016 est.)[8]'] = merged_df['Population (2016 est.)[8]'].astype(int)\n",
    "\n",
    "# Create the lists of the population and the ratio to estimate the correlation and p-value\n",
    "population_by_region_mlb = list(merged_df['Population (2016 est.)[8]'].values)\n",
    "win_loss_by_region_mlb = list(merged_df['Win-Loss Ratio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15027698302669307, 0.46370703378875583)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cda33b094ba19ccc37a481e0dd29e0bc",
     "grade": true,
     "grade_id": "cell-764d4476f425c5a2",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6977a6da9ed6d8b7a0b7e37bbeda709b",
     "grade": false,
     "grade_id": "cell-793df6c04dfb126e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 4\n",
    "For this question, calculate the win/loss ratio's correlation with the population of the city it is in for the **NFL** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c4914ad1e119278ec2bd567c52640b66",
     "grade": false,
     "grade_id": "cell-8ccebc209aeec8d9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "# Imports\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "\n",
    "# Functions\n",
    "def remove_character(data, char='*'):\n",
    "    # Search for * at the end and remove it if any, otherwise, return the string\n",
    "    for item in char:\n",
    "        if item == data[-1]:\n",
    "            return data.strip(char)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_region_four(team_last_word):\n",
    "    # Search for the team last name in all the teams\n",
    "    for teams in list(nfl_city_population['NFL'].values):\n",
    "        # If the team is found, return the Metropolitan area\n",
    "        if team_last_word in teams:\n",
    "            return nfl_city_population[nfl_city_population['NFL'] == teams].index[0]\n",
    "\n",
    "        \n",
    "def nfl_return_merged_data():\n",
    "    return merged_df_nfl\n",
    "\n",
    "\n",
    "# Only include data from year 2018\n",
    "nfl_df = nfl_df[nfl_df['year'] == 2018]\n",
    "\n",
    "# Remove the rows that contains eather ['AFC', 'NFC']\n",
    "nfl_df = nfl_df[~nfl_df['DSRS'].str.contains(pat='[A-Z]{3}', regex=True)]\n",
    "\n",
    "# Remove the characters ['*', '+'] from the team name\n",
    "nfl_df['team'] = nfl_df['team'].apply(lambda x: remove_character(x, '*+'))\n",
    "\n",
    "# Transform nfl_df Win and Loss from str() to int()\n",
    "nfl_df['W'] = nfl_df['W'].astype(int)\n",
    "nfl_df['L'] = nfl_df['L'].astype(int)\n",
    "\n",
    "# Estimate the Win/(Win + Loss) Ratio Column\n",
    "nfl_df['Win/Loss Ratio'] = nfl_df['W'] / (nfl_df['W'] + nfl_df['L'])\n",
    "\n",
    "# Remove [] from cities dataframe\n",
    "cities['NFL'] = cities['NFL'].apply(lambda x: remove_square_brackets(x))\n",
    "cities.replace(to_replace=['â€”', ''], value=np.nan, inplace=True)\n",
    "\n",
    "# Select the required columns and create nhl_city_population DataFrame and clean the data\n",
    "nfl_city_population = cities[['Metropolitan area', 'Population (2016 est.)[8]', 'NFL']]\n",
    "nfl_city_population.set_index('Metropolitan area', inplace=True)\n",
    "nfl_city_population.dropna(inplace=True, axis=0)\n",
    "nfl_city_population.drop('Toronto', inplace=True)\n",
    "\n",
    "# Create the region data from the title column and set it as the index of the df\n",
    "nfl_df['team_last_name'] = nfl_df['team'].apply(lambda x: x.split(' ')[-1])\n",
    "nfl_df['Region'] = nfl_df['team_last_name'].apply(lambda x: extract_region_four(x))\n",
    "nfl_df.set_index('Region', inplace=True)\n",
    "\n",
    "# groupby() the region column and estimate the mean ratio per region\n",
    "report_list = []\n",
    "\n",
    "for group, frame in nfl_df.groupby(by='Region'):\n",
    "    report_list.append({'Region': group, 'Win-Loss Ratio': frame['Win/Loss Ratio'].mean()})\n",
    "\n",
    "# Create DataFrame from the report\n",
    "report_df = pd.DataFrame(report_list).set_index('Region')\n",
    "\n",
    "# Merge report_df and nhl_city_population DataFrames\n",
    "merged_df_nfl = pd.merge(report_df, nfl_city_population, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Transform Population Columns from object to numeric\n",
    "merged_df_nfl['Population (2016 est.)[8]'] = merged_df_nfl['Population (2016 est.)[8]'].astype(int)\n",
    "\n",
    "# Create the lists of the population and the ratio to estimate the correlation and p-value\n",
    "population_by_region_nfl = list(merged_df_nfl['Population (2016 est.)[8]'].values)\n",
    "win_loss_by_region_nfl = list(merged_df_nfl['Win-Loss Ratio'].values)\n",
    "\n",
    "\n",
    "def nfl_correlation(): \n",
    "    # YOUR CODE HERE\n",
    "    global population_by_region_nfl\n",
    "    global win_loss_by_region_nfl\n",
    "\n",
    "    assert len(population_by_region_nfl) == len(win_loss_by_region_nfl), \"Q4: Your lists must be the same length\"\n",
    "    assert len(population_by_region_nfl) == 29, \"Q4: There should be 29 teams being analysed for NFL\"\n",
    "\n",
    "    corr, pval = stats.pearsonr(population_by_region_nfl, win_loss_by_region_nfl)\n",
    "    \n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004922112149349393"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfl_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "\n",
    "# Functions\n",
    "def remove_character(data, char='*'):\n",
    "    # Search for * at the end and remove it if any, otherwise, return the string\n",
    "    for item in char:\n",
    "        if item == data[-1]:\n",
    "            return data.strip(char)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_region_four(team_last_word):\n",
    "    # Search for the team last name in all the teams\n",
    "    for teams in list(nfl_city_population['NFL'].values):\n",
    "        # If the team is found, return the Metropolitan area\n",
    "        if team_last_word in teams:\n",
    "            return nfl_city_population[nfl_city_population['NFL'] == teams].index[0]\n",
    "\n",
    "\n",
    "# Only include data from year 2018\n",
    "nfl_df = nfl_df[nfl_df['year'] == 2018]\n",
    "\n",
    "# Remove the rows that contains eather ['AFC', 'NFC']\n",
    "nfl_df = nfl_df[~nfl_df['DSRS'].str.contains(pat='[A-Z]{3}', regex=True)]\n",
    "\n",
    "# Remove the characters ['*', '+'] from the team name\n",
    "nfl_df['team'] = nfl_df['team'].apply(lambda x: remove_character(x, '*+'))\n",
    "\n",
    "# Transform nfl_df Win and Loss from str() to int()\n",
    "nfl_df['W'] = nfl_df['W'].astype(int)\n",
    "nfl_df['L'] = nfl_df['L'].astype(int)\n",
    "\n",
    "# Estimate the Win/(Win + Loss) Ratio Column\n",
    "nfl_df['Win/Loss Ratio'] = nfl_df['W'] / (nfl_df['W'] + nfl_df['L'])\n",
    "\n",
    "# Remove [] from cities dataframe\n",
    "cities['NFL'] = cities['NFL'].apply(lambda x: remove_square_brackets(x))\n",
    "cities.replace(to_replace=['â€”', ''], value=np.nan, inplace=True)\n",
    "\n",
    "# Select the required columns and create nhl_city_population DataFrame and clean the data\n",
    "nfl_city_population = cities[['Metropolitan area', 'Population (2016 est.)[8]', 'NFL']]\n",
    "nfl_city_population.set_index('Metropolitan area', inplace=True)\n",
    "nfl_city_population.dropna(inplace=True, axis=0)\n",
    "nfl_city_population.drop('Toronto', inplace=True)\n",
    "\n",
    "# Create the region data from the title column and set it as the index of the df\n",
    "nfl_df['team_last_name'] = nfl_df['team'].apply(lambda x: x.split(' ')[-1])\n",
    "nfl_df['Region'] = nfl_df['team_last_name'].apply(lambda x: extract_region_four(x))\n",
    "nfl_df.set_index('Region', inplace=True)\n",
    "\n",
    "# groupby() the region column and estimate the mean ratio per region\n",
    "report_list = []\n",
    "\n",
    "for group, frame in nfl_df.groupby(by='Region'):\n",
    "    report_list.append({'Region': group, 'Win-Loss Ratio': frame['Win/Loss Ratio'].mean()})\n",
    "\n",
    "# Create DataFrame from the report\n",
    "report_df = pd.DataFrame(report_list).set_index('Region')\n",
    "\n",
    "# Merge report_df and nhl_city_population DataFrames\n",
    "merged_df = pd.merge(report_df, nfl_city_population, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Transform Population Columns from object to numeric\n",
    "merged_df['Population (2016 est.)[8]'] = merged_df['Population (2016 est.)[8]'].astype(int)\n",
    "\n",
    "# Create the lists of the population and the ratio to estimate the correlation and p-value\n",
    "population_by_region_nfl = list(merged_df['Population (2016 est.)[8]'].values)\n",
    "win_loss_by_region_nfl = list(merged_df['Win-Loss Ratio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e9415d6399aa49e3a1a60813afdefa3b",
     "grade": true,
     "grade_id": "cell-de7b148b9554dbda",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b02d5cd3273f561e4ae939bb2a41740c",
     "grade": false,
     "grade_id": "cell-97b49d8639e908c4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 5\n",
    "In this question I would like you to explore the hypothesis that **given that an area has two sports teams in different sports, those teams will perform the same within their respective sports**. How I would like to see this explored is with a series of paired t-tests (so use [`ttest_rel`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html)) between all pairs of sports. Are there any sports where we can reject the null hypothesis? Again, average values where a sport has multiple teams in one region. Remember, you will only be including, for each sport, cities which have teams engaged in that sport, drop others as appropriate. This question is worth 20% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6d78c961eb66f8d8c81f06d33ae8f393",
     "grade": false,
     "grade_id": "cell-92f25f44b8d1179f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "\n",
    "# Import data\n",
    "mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "nba_df=pd.read_csv(\"assets/nba.csv\")\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "#####################################################################################\n",
    "# Functions\n",
    "def remove_square_brackets(data):\n",
    "# Search for everything between the square brackets [] and replace it with '' if any, otherwise, return the string\n",
    "    if re.search(\"\\[(.*?)\\]\", data) is None:\n",
    "        return data\n",
    "    else:\n",
    "        return data.replace(re.search(\"\\[(.*?)\\]\", data).group(), '')\n",
    "        \n",
    "        \n",
    "def estimate_pvalue_for_sport(data):\n",
    "    p_values_list = []\n",
    "    for sport in sports:\n",
    "        df = pd.merge(left=dfs[data], right=dfs[sport], how='inner', left_index=True, right_index=True)\n",
    "        p_value = stats.ttest_rel(df['Win-Loss Ratio_x'], df['Win-Loss Ratio_y'])[1]\n",
    "        p_value = round(p_value, 2)\n",
    "        p_values_list.append(p_value)\n",
    "    return p_values_list\n",
    "        \n",
    "# Import Merged data from Q1 - Q4    \n",
    "nba_merged_df = nba_return_merged_data().drop(columns='Population (2016 est.)[8]', axis=1)\n",
    "nfl_merged_df = nfl_return_merged_data().drop(columns='Population (2016 est.)[8]', axis=1)\n",
    "nhl_merged_df = nhl_return_merged_data().drop(columns='Population (2016 est.)[8]', axis=1)\n",
    "mlb_merged_df = mlb_return_merged_data().drop(columns='Population (2016 est.)[8]', axis=1)\n",
    "\n",
    "# Clean the columns from cities dataframe\n",
    "# Remove the square brackets '[]'\n",
    "cities['NFL'] = cities['NFL'].apply(lambda x: remove_square_brackets(x))\n",
    "cities['MLB'] = cities['MLB'].apply(lambda x: remove_square_brackets(x))\n",
    "cities['NHL'] = cities['NHL'].apply(lambda x: remove_square_brackets(x))\n",
    "cities['NBA'] = cities['NBA'].apply(lambda x: remove_square_brackets(x))\n",
    "\n",
    "# Replace the ['-', ''] for NaN values\n",
    "cities.replace(to_replace=['â€”', 'â€” ', ''], value=np.nan, inplace=True)\n",
    "\n",
    "# Create a dictionary to hold the DataFrames with their name as key\n",
    "dfs = {'NFL': nfl_merged_df,\n",
    "       'NBA': nba_merged_df,\n",
    "       'MLB': mlb_merged_df,\n",
    "       'NHL': nhl_merged_df}\n",
    "\n",
    "sports = ['NFL', 'NBA', 'NHL', 'MLB']\n",
    "\n",
    "\n",
    "def sports_team_performance():\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    # Note: p_values is a full dataframe, so df.loc[\"NFL\",\"NBA\"] should be the same as df.loc[\"NBA\",\"NFL\"] and\n",
    "    # df.loc[\"NFL\",\"NFL\"] should return np.nan\n",
    "    sports = ['NFL', 'NBA', 'NHL', 'MLB']\n",
    "    p_values = pd.DataFrame({k: estimate_pvalue_for_sport(k) for k in sports}, index=sports)\n",
    "    \n",
    "    assert abs(p_values.loc[\"NBA\", \"NHL\"] - 0.02) <= 1e-2, \"The NBA-NHL p-value should be around 0.02\"\n",
    "    assert abs(p_values.loc[\"MLB\", \"NFL\"] - 0.80) <= 1e-2, \"The MLB-NFL p-value should be around 0.80\"\n",
    "    return p_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NHL</th>\n",
       "      <th>MLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NFL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBA</th>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHL</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLB</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NFL   NBA   NHL   MLB\n",
       "NFL   NaN  0.94  0.03  0.80\n",
       "NBA  0.94   NaN  0.02  0.95\n",
       "NHL  0.03  0.02   NaN  0.00\n",
       "MLB  0.80  0.95  0.00   NaN"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "\n",
    "# Import data\n",
    "mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "nba_df=pd.read_csv(\"assets/nba.csv\")\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "#####################################################################################\n",
    "# Functions\n",
    "def remove_square_brackets(data):\n",
    "# Search for everything between the square brackets [] and replace it with '' if any, otherwise, return the string\n",
    "    if re.search(\"\\[(.*?)\\]\", data) is None:\n",
    "        return data\n",
    "    else:\n",
    "        return data.replace(re.search(\"\\[(.*?)\\]\", data).group(), '')\n",
    "        \n",
    "nba_merged_df = nba_return_merged_data().drop(columns='Population (2016 est.)[8]', axis=1)\n",
    "nfl_merged_df = nfl_return_merged_data().drop(columns='Population (2016 est.)[8]', axis=1)\n",
    "nhl_merged_df = nhl_return_merged_data().drop(columns='Population (2016 est.)[8]', axis=1)\n",
    "mlb_merged_df = mlb_return_merged_data().drop(columns='Population (2016 est.)[8]', axis=1)\n",
    "\n",
    "# Clean the columns from cities dataframe\n",
    "# Remove the square brackets '[]'\n",
    "cities['NFL'] = cities['NFL'].apply(lambda x: remove_square_brackets(x))\n",
    "cities['MLB'] = cities['MLB'].apply(lambda x: remove_square_brackets(x))\n",
    "cities['NHL'] = cities['NHL'].apply(lambda x: remove_square_brackets(x))\n",
    "cities['NBA'] = cities['NBA'].apply(lambda x: remove_square_brackets(x))\n",
    "# Replace the ['-', ''] for NaN values\n",
    "cities.replace(to_replace=['â€”', 'â€” ', ''], value=np.nan, inplace=True)\n",
    "\n",
    "# Create a dictionary to hold the DataFrames with their name as key\n",
    "dfs = {'NFL': nfl_merged_df,\n",
    "      'NBA': nba_merged_df,\n",
    "      'MLB': mlb_merged_df,\n",
    "      'NHL': nhl_merged_df}\n",
    "\n",
    "sports = ['NFL', 'NBA', 'NHL', 'MLB']\n",
    "\n",
    "\n",
    "def estimate_pvalue_for_sport(data):\n",
    "    p_values_list = []\n",
    "    for sport in sports:\n",
    "        df = pd.merge(left=dfs[data], right=dfs[sport], how='inner', left_index=True, right_index=True)\n",
    "        p_value = stats.ttest_rel(df['Win-Loss Ratio_x'], df['Win-Loss Ratio_y'])[1]\n",
    "        p_value = round(p_value, 2)\n",
    "        p_values_list.append(p_value)\n",
    "    \n",
    "    return p_values_list\n",
    "\n",
    "sports_team_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2a596ab421a45cc01168d10e8fbb8f89",
     "grade": true,
     "grade_id": "cell-fb4b9cb5ff4570a6",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mooc_adswpy_1_v2_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
